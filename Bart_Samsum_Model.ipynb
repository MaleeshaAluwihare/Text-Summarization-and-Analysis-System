{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration            # BERT Tokenizer and architecture\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments               # fine-tune model\n",
    "from transformers import pipeline                                               # pipeline\n",
    "from transformers import DataCollatorForSeq2Seq                                 # DataCollator to batch the data\n",
    "import torch                                                                    # PyTorch\n",
    "import evaluate                                                                 # Hugging Face's library for model evaluation\n",
    "from datasets import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# from textblob import TextBlob                                                 # fix spelling mistakes in texts\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer                     # identify the most common terms in the corpus\n",
    "import re                                                                       # clean text data\n",
    "nltk.download('punkt')                                                          # divides a text into a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available - Using GPU\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"GPU is not available - Using CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to fully read the dialogues and its summary \n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_list(features, feature_type):\n",
    "\n",
    "    '''\n",
    "    This function displays the features within each list for each type of data\n",
    "    '''\n",
    "\n",
    "    print(f\"\\n{feature_type} Features: \")\n",
    "    print(', '.join(features) if features else 'None')\n",
    "\n",
    "def describe_df(df):\n",
    "    \n",
    "    global categorical_features\n",
    "    categorical_features = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "    print(f\"\\n{type(df).__name__} shape: {df.shape}\")\n",
    "    print(f\"\\n{df.shape[0]:,.0f} samples\")\n",
    "    print(f'\\nMissing Data: \\n{df.isnull().sum()}')\n",
    "    print(f'\\nDuplicates: {df.duplicated().sum()}')\n",
    "\n",
    "    display_feature_list(categorical_features, 'Categorical')\n",
    "\n",
    "    print(f'\\n{type(df).__name__} Head: \\n')\n",
    "    display(df.head(5))\n",
    "    print(f'\\n{type(df).__name__} Tail: \\n')\n",
    "    display(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train_df = pd.read_csv('Datasets/samsum/samsum-train.csv')\n",
    "test_df = pd.read_csv('Datasets/samsum/samsum-test.csv')\n",
    "val_df = pd.read_csv('Datasets/samsum/samsum-validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting info on the training Dataframe\n",
    "describe_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the dialogues is empty\n",
    "# null dialogues\n",
    "NullRaws = train_df['dialogue'].isnull()\n",
    "filtered_train = train_df[NullRaws] \n",
    "filtered_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all null values\n",
    "train_df = train_df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'Id' from categorical features list\n",
    "categorical_features.remove('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting info on the test dataset\n",
    "describe_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'Id' from categorical features list\n",
    "categorical_features.remove('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting info on the val dataset\n",
    "describe_df(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'Id' from categorical features list\n",
    "categorical_features.remove('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text that contain tags\n",
    "print(test_df['dialogue'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text that contain tags\n",
    "print(train_df['dialogue'].iloc[14727])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for clean tags and empty lines\n",
    "def clean_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    clean = re.sub(clean, '', text) #Replacing tags text by an empty string\n",
    "\n",
    "    clean = '\\n'.join([line for line in clean.split('\\n') if not re.match(r'.*:\\s*$',line)]) # Removing empty dialogues\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for clean tags\n",
    "test1 = clean_tags(train_df['dialogue'].iloc[14727]) # Applying function to example text\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean tags function for entire dataset\n",
    "def clean_df(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna('').apply(clean_tags)\n",
    "    return df\n",
    "\n",
    "# Cleaning texts in all datasets\n",
    "train_df = clean_df(train_df,['dialogue', 'summary'])\n",
    "test_df = clean_df(test_df,['dialogue', 'summary'])\n",
    "val_df = clean_df(val_df,['dialogue', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming dataframes into datasets\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Visualizing results\n",
    "print(train_ds)\n",
    "print('\\n' * 2)\n",
    "print(test_ds)\n",
    "print('\\n' * 2)\n",
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading summarization pipeline with the bart-large-cnn model\n",
    "summarizer = pipeline('summarization', model = 'facebook/bart-large-xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Hugging Face's transformers library provides many tools for modern NLP tasks.\n",
    "          With pipelines, you can easily load models and perform complex tasks like\n",
    "          text generation, summarization, or translation with minimal code.\"\"\"\n",
    "\n",
    "news = '''Bobi, the world’s oldest dog ever, has died after reaching the almost inconceivable age of 31 years and 165 days, said Guinness World Records (GWR) on Monday.\n",
    "His death at an animal hospital on Friday was initially announced by veterinarian Dr. Karen Becker.\n",
    "She wrote on Facebook that “despite outliving every dog in history, his 11,478 days on earth would never be enough, for those who loved him.”\n",
    "There were many secrets to Bobi’s extraordinary old age, his owner Leonel Costa told GWR in February. He always roamed freely, without a leash or chain, lived in a “calm, peaceful” environment and ate human food soaked in water to remove seasonings, Costa said.\n",
    "He spent his whole life in Conqueiros, a small Portuguese village about 150 kilometers (93 miles) north of the capital Lisbon, often wandering around with cats.\n",
    "Bobi was a purebred Rafeiro do Alentejo – a breed of livestock guardian dog – according to his owner. Rafeiro do Alentejos have a life expectancy of about 12-14 years, according to the American Kennel Club.\n",
    "But Bobi lived more than twice as long as that life expectancy, surpassing an almost century-old record to become the oldest living dog and the oldest dog ever – a title which had previously been held by Australian cattle-dog Bluey, who was born in 1910 and lived to be 29 years and five months old.\n",
    "However, Bobi’s story almost had a different ending.\n",
    "When he and his three siblings were born in the family’s woodshed, Costa’s father decided they already had too many animals at home.\n",
    "Costa and his brothers thought their parents had taken all the puppies away to be destroyed. However, a few sad days later, they found Bobi alive, safely hidden in a pile of logs.\n",
    "The children hid the puppy from their parents and, by the time Bobi’s existence became known, he was too old to be put down and went on to live his record-breaking life.\n",
    "His 31st birthday party in May was attended by more than 100 people and a performing dance troupe, GWR said.\n",
    "His eyesight deteriorated and walking became harder as Bobi grew older but he still spent time in the backyard with the cats, rested more and napped by the fire.\n",
    "“Bobi is special because looking at him is like remembering the people who were part of our family and unfortunately are no longer here, like my father, my brother, or my grandparents who have already left this world,” Costa told GWR in May. “Bobi represents those generations.”\n",
    "'''\n",
    "\n",
    "chat = '''\n",
    "Theresa: Hey Louise, how are u?\n",
    "Theresa: This is my workplace, they always give us so much food here 😊\n",
    "Theresa: Luckily they also offer us yoga classes, so all the food isn't much of a problem 😂\n",
    "Louise: Hey!! 🙂 \n",
    "Louise: Wow, that's awesome, seems great 😎 Haha\n",
    "Louise: I'm good! Are you coming to visit Stockholm this summer? 🙂\n",
    "Theresa: I don't think so :/ I need to prepare for Uni.. I will probably attend a few lessons this winter\n",
    "Louise: Nice! Do you already know which classes you will attend?\n",
    "Theresa: Yes, it will be psychology :) I want to complete a few modules that I missed :)\n",
    "Louise: Very good! Is it at the Uni in Prague?\n",
    "Theresa: No, it will be in my home town :)\n",
    "Louise: I have so much work right now, but I will continue to work until the end of summer, then I'm also back to Uni, on the 26th September!\n",
    "Theresa: You must send me some pictures, so I can see where you live :) \n",
    "Louise: I will, and of my cat and dog too 🤗\n",
    "Theresa: Yeeeesss pls :)))\n",
    "Louise: 👌👌\n",
    "Theresa: 🐱💕'''\n",
    "\n",
    "\n",
    "summary1 = summarizer(text)\n",
    "summary2 = summarizer(news)\n",
    "summary3 = summarizer(chat)\n",
    "\n",
    "print(summary1)\n",
    "print(\"\\n\"*2)\n",
    "print(summary2)\n",
    "print(\"\\n\"*2)\n",
    "print(summary3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above result model is able to accurately produce a much shorter text. However its not capabel to summarise Dialogs accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facebook/bart-large-xsum'                  # model name\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)    # Loading Tokanizer\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model) # Visualizing model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocess datasets\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"dialogue\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying preprocess_function to the datasets\n",
    "tokenized_train = train_ds.map(preprocess_function, batched=True,\n",
    "                               remove_columns=['id', 'dialogue', 'summary', '__index_level_0__']) # Removing features\n",
    "\n",
    "tokenized_test = test_ds.map(preprocess_function, batched=True,\n",
    "                               remove_columns=['id', 'dialogue', 'summary']) # Removing features\n",
    "\n",
    "tokenized_val = val_ds.map(preprocess_function, batched=True,\n",
    "                               remove_columns=['id', 'dialogue', 'summary']) # Removing features\n",
    "\n",
    "# Printing results\n",
    "print('\\n' * 3)\n",
    "print('Preprocessed Training Dataset:\\n')\n",
    "print(tokenized_train)\n",
    "print('\\n' * 2)\n",
    "print('Preprocessed Test Dataset:\\n')\n",
    "print(tokenized_test)\n",
    "print('\\n' * 2)\n",
    "print('Preprocessed Validation Dataset:\\n')\n",
    "print(tokenized_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a sample from the dataset\n",
    "sample = tokenized_train[0]\n",
    "\n",
    "# Printing its features\n",
    "print(\"input_ids:\")                    # These are the token IDs mapped to the dialogues\n",
    "print(sample['input_ids'])\n",
    "print(\"\\n\")\n",
    "print(\"attention_mask:\")               # indicates which tokens the model should pay attention to and which tokens should be ignored\n",
    "print(sample['attention_mask'])\n",
    "print(\"\\n\")\n",
    "print(\"sample:\")                       # token IDs obtained from the words and subwords in the summaries\n",
    "print(sample['labels'])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Data Collator to batch the data\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ROUGE Score\n",
    "metric = evaluate.load('rouge') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred# Obtaining predictions and true labels\n",
    "    \n",
    "    # Decoding predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Obtaining the true labels tokens, while eliminating any possible masked token (i.e., label = -100)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    \n",
    "    # Computing rouge score\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()} # Extracting some results\n",
    "\n",
    "    # Add mean-generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for training\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = 'Bart_Samsum',\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 500,\n",
    "    save_strategy = 'steps',\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'eval_loss',\n",
    "    seed = 42,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating and Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model performance on the tokenized validation dataset\n",
    "validation = trainer.evaluate(eval_dataset = tokenized_val)\n",
    "\n",
    "print(validation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model \n",
    "directory = \"BART_Finetuned\"\n",
    "trainer.save_model(directory)\n",
    "\n",
    "# Saving model tokenizer\n",
    "tokenizer.save_pretrained(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading summarization pipeline and model\n",
    "\n",
    "# summarizer  = pipeline(\"text2text-generation\", model=\"MaleeshaAlu/Bart_Samsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examples from the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random example from the validation dataset\n",
    "# val_ds[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialogue = \"John: doing anything special?\\r\\nAlex: watching 'Millionaires' on tvn\\r\\nSam: me too! He has a chance to win a million!\\r\\nJohn: ok, fingers crossed then! :)\"\n",
    "# summary = 'Alex and Sam are watching Millionaires.'\n",
    "\n",
    "# generated_summary = summarizer(dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Original Dialogue:\\n')\n",
    "# print(dialogue)\n",
    "# print('\\n' * 2)\n",
    "# print('Reference Summary:\\n')\n",
    "# print(summary)\n",
    "# print('\\n' * 2)\n",
    "# print('Model-generated Summary:\\n')\n",
    "# print(generated_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
